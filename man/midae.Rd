% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/midae.R
\name{midae}
\alias{midae}
\title{Multiple imputation through denoising autoencoders with dropout (Use embeddings)}
\usage{
midae(
  data,
  m = 5,
  categorical.encoding = "embeddings",
  device = "cpu",
  epochs = 5,
  batch.size = 32,
  subsample = 1,
  early.stopping.epochs = 1,
  dae.params = list(),
  pmm.params = list(),
  loss.na.scale = FALSE,
  verbose = TRUE,
  print.every.n = 1,
  save.model = FALSE,
  path = NULL
)
}
\arguments{
\item{data}{A data frame, tibble or data table with missing values.}

\item{m}{The number of imputed datasets.}

\item{categorical.encoding}{The method for representing multi-class categorical features. Can be either "embeddings" or "onehot".}

\item{device}{Device to use. Either "cpu" or "cuda" for GPU.}

\item{epochs}{The number of training epochs (iterations).}

\item{batch.size}{The size of samples in each batch. Default: 32.}

\item{subsample}{The subsample ratio of training data. Default: 1.}

\item{early.stopping.epochs}{An integer value \code{k}. Mivae training will stop if the validation performance has not improved for \code{k} epochs, only used when \code{subsample}<1. Default: 10.}

\item{loss.na.scale}{Whether to multiply the ratio of missing values in  a feature to calculate the loss function. Default: FALSE.}

\item{verbose}{Whether or not to print training loss information. Default: TRUE.}

\item{print.every.n}{If verbose is set to TRUE, print out training loss for every n epochs.}

\item{save.model}{Whether or not to save the imputation model. Default: FALSE.}

\item{path}{The path where the final imputation model will be saved.}

\item{pmm.type}{The type of predictive mean matching (PMM). Possible values:
\itemize{
\item \code{NULL}: Imputations without PMM;
\item \code{0}: Imputations with PMM type 0;
\item \code{1}: Imputations with PMM type 1;
\item \code{2}: Imputations with PMM type 2;
\item \code{"auto"} (Default): Imputations with PMM type 2 for numeric/integer variables; imputations without PMM for categorical variables.
}}

\item{pmm.k}{The number of donors for predictive mean matching. Default: 5}

\item{pmm.link}{The link for predictive mean matching in binary variables
\itemize{
\item \code{"prob"} (Default): use probabilities;
\item \code{"logit"}: use logit values.
}}

\item{pmm.save.vars}{The names of variables whose predicted values of observed entries will be saved. Only use for PMM.}

\item{drop.last}{Whether or not to drop the last batch. Default: FALSE}

\item{shuffle}{Whether or not to shuffle training data. Default: TRUE}

\item{input.dropout}{The dropout probability of the input layer.}

\item{hidden.dropout}{The dropout probability of the hidden layers.}

\item{optimizer}{The name of the optimizer. Options are : "adamW" (default), "adam" and "sgd".}

\item{learning.rate}{The learning rate. The default value is 0.001.}

\item{weight.decay}{Weight decay (L2 penalty). The default value is 0.}

\item{momentum}{Parameter for "sgd" optimizer. It is used for accelerating SGD in the relevant direction and dampens oscillations.}

\item{eps}{A small positive value used to prevent division by zero for the "adamW" optimizer. Default: 1e-07.}

\item{encoder.structure}{A vector indicating the structure of encoder. Default: c(128,64,32)}

\item{latent.dim}{The size of latent layer. The default value is 16.}

\item{decoder.structure}{A vector indicating the structure of decoder. Default: c(32,64,128)}

\item{act}{The name of activation function. Can be: "relu", "elu", "leaky.relu", "tanh", "sigmoid" and "identity".}

\item{init.weight}{Techniques for weights initialization. Can be "xavier.uniform", "xavier.normal" or "xavier.midas" (or "kaiming.uniform")}

\item{scaler}{The name of scaler for transforming numeric features. Can be "standard", "minmax" ,"decile" or "none".}
}
\description{
Multiple imputation through denoising autoencoders with dropout (Use embeddings)
}
\examples{
withNA.df <- createNA(data = iris, p = 0.2)
imputed.data <- midae(data = withNA.df, m = 5, epochs = 5, path = file.path(tempdir(), "midaemodel.pt"))
}
